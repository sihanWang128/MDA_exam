{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7734100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e2401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url):\n",
    "    \n",
    "    page = urllib.request.urlopen(url)\n",
    "\n",
    "#Cooking the Soup\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "\n",
    "    web_list=[]\n",
    "#Scraping \"Link\" (href)\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        web_list.append(a[\"href\"])\n",
    "    speech=[]\n",
    "    for i in web_list:\n",
    "        if i.startswith(\"speeches\"):\n",
    "            speech.append(i)\n",
    "    speech_web=[]\n",
    "    for i in speech:\n",
    "        if i.endswith('htm'):\n",
    "            speech_web.append(i)\n",
    "    \n",
    "    return speech_web\n",
    "\n",
    "def modify_url(speech_web):\n",
    "    start = speech_web.index('speeches/barackobama/barackobamainauguraladdress.htm')\n",
    "    speech_president = speech_web[start:]\n",
    "\n",
    "# remove replicate\n",
    "    new = []\n",
    "    for i in speech_president:\n",
    "        if i not in new:\n",
    "            new.append(i)\n",
    "\n",
    "    speech_url = []\n",
    "    for val in range(len(new)):\n",
    "        speech_url.append(\"https://www.americanrhetoric.com/\" + str(new[val])) \n",
    "   \n",
    "    return speech_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5f1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(url):\n",
    "        user = {\n",
    "            'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\"\n",
    "        }\n",
    "        resp = requests.get(url, headers=user)\n",
    "        soup = BeautifulSoup(resp.text, \"html\")\n",
    "       \n",
    "        content=soup.find_all(\"font\",face=\"Verdana\", size=\"2\")\n",
    "        l=[]\n",
    "        speech={}\n",
    "\n",
    "        speech['url']=url\n",
    "        for i in range(len(content)):\n",
    "            l.append(content[i].text.replace('\\r\\n\\t\\t', ' ').strip())\n",
    "        speech['content']=''\n",
    "        for x in l:\n",
    "            x=x.replace(\"\\'\", ' ').strip()\n",
    "            speech['content']+=\" \"+x\n",
    "        return speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae33bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title(url):\n",
    "    user = {'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\"}\n",
    "    resp = requests.get(url, headers=user)\n",
    "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "        \n",
    "    title=soup.find_all('font', color=\"#000048\")\n",
    "    title_list=[]\n",
    "    for i in range(len(title)):\n",
    "            title_list.append(title[i].text)\n",
    "    return title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9a03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(url):\n",
    "        user = {'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\"}\n",
    "        resp = requests.get(url, headers=user)\n",
    "        soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "        \n",
    "        date=soup.find_all('font', size=\"4\", face=\"Tahoma\")\n",
    "        date_list=[]\n",
    "        for i in range(len(date)):\n",
    "            date_list.append(date[i].text)\n",
    "        return date_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd10d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://www.americanrhetoric.com/barackobamaspeeches.htm\"\n",
    "speech_web=get_url(url)\n",
    "speech_url=modify_url(speech_web)\n",
    "    \n",
    "date=extract_date(url)\n",
    "date_list=date[date.index(\"20 Jan 2009\"):]\n",
    "title=extract_title(url)\n",
    "for i in date[:]:\n",
    "    if i in title:\n",
    "        title.remove(i)\n",
    "title=list(filter(lambda a: a != 'O', title))\n",
    "title=list(filter(lambda a: a != 'รง', title))\n",
    "title=list(filter(lambda a: a != 'ois \\r\\n\\t\\t\\tHollande', title))\n",
    "title_list=title[title.index('FIRST PRESIDENTIAL INAUGURAL ADDRESS'):]\n",
    "    \n",
    "\n",
    "data_list=[]\n",
    "for i in range(len(speech_url)):\n",
    "    data_list.append(extract_text(speech_url[i]))\n",
    "df=pd.DataFrame(data_list)\n",
    "df['title']=title_list\n",
    "df['date']=date_list\n",
    "    \n",
    "df.to_csv('obama_speech.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762bc3b7",
   "metadata": {},
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
